by B. J. Rhodes
P . Maes
A just-in-time information retrieval agent (JITIR
agent) is software that proactively retrieves andpresents information based on a person’s localcontext in an easily accessible yet nonintrusivemanner. This paper describes three implementedJITIR agents: the Remembrance Agent, MarginNotes, and Jimminy. Theory and design lessonslearned from these implementations arepresented, drawing from behavioral psychology,information retrieval, and interface design. Theyare followed by evaluations and experimentalresults. The key lesson is that users of JITIRagents are not merely more efﬁcient at retrievinginformation, but actually retrieve and use moreinformation than they would with traditionalsearch engines.
In this paper, just-in-time information retrieval
agents ( JITIR agents) are introduced. JITIR agents
(pronounced “jitter agents”) are a class of software
agents that proactively present information based ona person’s context in an easily accessible and non-intrusive manner. They continuously watch a per-son’s environment and present information that maybe useful without requiring any action on the partof the user. The environment that an agent looks atis usually computational: e-mail, a Web page that aperson is reading, or a document that he or she iswriting. However, it can also be a person’s physicalenvironment as sensed by a hand-held or wearablecomputer. The information a
JITIR agent provides
can come from any number of preindexed databasesof documents, e.g., e-mail archives, notes ﬁles, ordocuments from commercial databases such as the
INSPEC collection of the Institute of Electrical and
Electronics Engineers ( IEEE ) technical paper ab-
stracts. A key feature of a JITIR agent is that it canprovide information from an unordered set of doc-uments; no hand-coding of documents or special do-main-dependent techniques are required. This fea-ture makes it easy to adapt systems to new domainsand information sources.
The word “agent” has many different deﬁnitions.
JITIR agents are “software agents” in that they are
long-lived, watch an environment, and can take ac-
tion based on that environment without direct userintervention. They should not be confused with “em-bodied conversational agents” or synthetic charac-ters, which are graphical interactive characters thatpresent a personality and interact with a user in ananimistic way. They should also not be confused withdistributed agent architectures or agent-orientedprogramming models, which are both architecturesfor software design rather than a class of applica-tions. Unless speciﬁed, all references to the word“agents” in this document speciﬁcally mean
JITIR
agents.
The three necessary features of a JITIR agent are pro-
activity, the presentation of information in an acces-
sible yet nonintrusive manner, and awareness of theuser’s local context. These three features make
JITIR
agents similar to search engines, alarms, and person-alized help systems, although they differ from each.
rCopyright 2000 by International Business Machines Corpora-
tion. Copying in printed form for private use is permitted with-
out payment of royalty provided that (1) each reproduction is donewithout alteration and (2) the Journal reference and IBM copy-
right notice are included on the ﬁrst page. The title and abstract,but no other portions, of this paper may be copied or distributedroyalty free without further permission by computer-based andother information-service systems. Permission to republish any
other portion of this paper must be obtained from the Editor.
IBM SYSTEMS JOURNAL, VOL 39, NOS 3&4, 2000 0018-8670/00/$5.00 © 2000 IBM RHODES AND MAES 685Just-in-t ime
inform ation
retrieval agents
Authorized licensed use limited to: Georgia Institute of Technology. Downloaded on September 10,2020 at 15:52:31 UTC from IEEE Xplore.  Restrictions apply.  Before the main discussion of the paper is begun,
the similarities and differences are discussed below.
Search engines and structured knowledge bases such
as Yahoo!** are inherently interactive: an informa-tion seeker has some query in mind and directly in-teracts with the program to obtain the desired in-formation.
JITIR agents, in contrast, are proactive.
The user need not have a query in mind, or evenknow that information relevant to his or her situ-ation exists. This proactivity has ramiﬁcations for theinformation retrieval techniques that can be used,because the “query” utilized is limited to what canbe sensed in the environment. It also has ramiﬁca-tions for interface design, because proactively dis-played information can be far more distracting thanrequested information.
When a cellular (cell) phone rings, it provides the
information that a person is calling and may also in-dicate the identity of the caller by the tone of thering. A ringing telephone is an alarm. It calls the useraway from whatever task is currently being per-formed and cannot easily be ignored. If the cellphone is turned off, the caller is often forwarded tovoice mail. A silent cell phone is extremely nonin-trusive, but without the ringer it is necessary to callthe voice-mail service directly to determine whetheranyone has called. The information about who called(if anyone) is less accessible than when it was indi-cated by the ring.
JITIR agents are designed to op-
erate in between these two extremes by presentinginformation in such a way that it can be ignored, butis still easy to access should it be desirable. Ratherthan presuppose whether or not a particular pieceof information is important or urgent,
JITIR agents
allow the user to decide whether to view or ignoreit, depending on the user’s current task and level ofcognitive load.
Notiﬁcation systems such as newspaper clipping ser-
vices and alerts are proactive, but the informationthey present is based on events outside of the user’slocal context. For example, an alert might be trig-gered whenever a new piece of e-mail arrives, a stockprice goes below a certain threshold, or news thatﬁts a user’s personal proﬁle hits the news wire. Thenotiﬁcations are designed to pull a person out of hisor her current context (task) and provide informa-tion about a different context that might require at-tention. The urgency of a notiﬁcation can range fromthe immediacy of a ﬁre alarm to a news brieﬁng thatis announced but intended to be read whenever con-venient.Notiﬁcation systems present information from a rap-idly changing source (e.g., current stock prices),based on relevance to a mostly static user proﬁle.
JITIR agents are the reverse: they provide informa-
tion from a mostly static source (e.g., e-mail archives)based on relevance to a user’s rapidly changing lo-cal context. Information provided by an agent is notmeant to pull a person out of his or her current con-text, but rather to add additional information thatmight be useful within that context.
In summary,
JITIR agents are similar to search en-
gines, alarms, and notiﬁcation systems, but none ofthese systems has all three features necessary for
JITIR agents: proactivity, a nonintrusive yet acces-
sible interface, and attention to local context.
Note that automatic help systems, such as the Mi-
crosoft Ofﬁce Assistant**, ﬁt the deﬁnition of a JITIR
agent. However, these systems are domain-speciﬁc;they only provide information from a specialized helpdatabase, using information-retrieval techniques thatare speciﬁc for that particular help domain. Althoughno system can support every possible domain andenvironment, the
JITIR agents described in this pa-
per are designed to provide information from a widevariety of sources using techniques that can be ap-plied to a wide variety of task domains.
Implementations
Three
JITIR agents have been deployed in the course
of this research. The ﬁrst and oldest is the Remem-
brance Agent ( RA), an agent that operates within the
Emacs text editor, a program developed at the Mas-sachusetts Institute of Technology (
MIT). The sec-
ond implementation is Margin Notes, a Web-basedagent that automatically annotates Web pages as theyare being loaded into a browser. The third systemis Jimminy (also called the Wearable
RA). Jimminy
presents information via a head-mounted display at-tached to a wearable computer, based on a person’sphysical environment: where the person is, who heor she is talking to, the time of day, etc. The systemdemonstrates the multidimensional aspects of the in-formation retrieval system used and how these agentscan be applied “off the desktop.”
All three systems use the same information retrieval
back end, called Savant, which was developed at the
MIT Media Laboratory especially for this research.
Savant uses a template structure to identify ﬁle typesand parse out individual documents and ﬁelds. Forexample, it can identify a mail archive ﬁle and index
RHODES AND MAES IBM SYSTEMS JOURNAL, VOL 39, NOS 3&4, 2000 686
Authorized licensed use limited to: Georgia Institute of Technology. Downloaded on September 10,2020 at 15:52:31 UTC from IEEE Xplore.  Restrictions apply.  individual e-mail documents by the from ﬁeld, sub-
ject line, date, and body of the message. Savant canalso handle multiple data types including the
GPS
(Global Positioning System) and date as well as rawtext, and can be easily extended to include more typesof ﬁelds and similarity metrics.
The Remembrance Agent. Emacs is a popular text
editor for the
UNIX ** operating system. Although
it is often used for traditional text-editing tasks such
as writing papers or computer code, the editor is pow-erful enough that it is also used for reading and writ-ing e-mail and network news, and even browsing theWeb. Emacs supports the use of multiple buffers,with each buffer containing a different ﬁle.
The
RA1continually presents a list of documents that
are related to the current document being written
or read. These suggestions appear in order of rel-evance within a special display buffer at the bottomof the Emacs window. When the user is typing, read-ing e-mails, or otherwise changing his or her envi-ronment, the list is updated every few seconds. Sug-gestions from multiple databases can be listed in thedisplay buffer, each with a certain number of lines.For example, the system can be conﬁgured to dis-play suggestions from e-mail archives in the ﬁrst fourlines and suggestions from note ﬁles in the next twolines. The display can also show different “scopes”from the same database, e.g., the ﬁrst few lines canshow suggestions based on the past 20 words,whereas the others can show suggestions based onthe past 500 words.
Figure 1 shows a screen shot of the
RAwhen writing
an earlier version of the introduction to this paper.
In this case, the documents being suggested comefrom a subset of the
INSPEC database of paper ab-
stracts (about 150000 citations). The suggestions areall for papers that might be relevant to the sectionbeing written. The full Emacs window is larger innormal operation, which means a larger ratio of ed-itor lines to
RA-suggestion lines.
The summary lines are a combination of ﬁelds in thedocument and are designed to give the user an in-dication of the content of the document as quicklyas possible. These summary lines can be customizedfor individual databases. For example, suggestionsfrom the
INSPEC database display author, date ofFigure 1    RA main display
IBM SYSTEMS JOURNAL, VOL 39, NOS 3&4, 2000 RHODES AND MAES 687
Authorized licensed use limited to: Georgia Institute of Technology. Downloaded on September 10,2020 at 15:52:31 UTC from IEEE Xplore.  Restrictions apply.  publication, and paper title. Articles from The Bos-
ton Globe, in contrast, use a longer ﬁeld to show
headlines and show publication date, but do not showthe author of the article. All summary lines also in-clude a relevance score, consisting of zero, one, ortwo plus signs. By default, if a suggestion is belowa minimum threshold, it is not displayed, and “Nosuggestion” is shown instead. It is also possible toconﬁgure the system to display below-threshold sug-gestions with a minus sign as the relevance.
Right-clicking on a suggestion causes a small pop-up
window to display the keywords that lead to the ab-stract being suggested. These keywords are also dis-played to the far right of the suggestion line, althoughdue to space constraints they are only visible whenthe user has a wide display window. To see the fulltext being suggested, the user types a keyboard short-cut or clicks on the desired line number. The full textthen replaces the current display buffer, as shown inFigure 2. By default the
RAwill not make sugges-
tions based on a suggestion that has been retrieved,though this is customizable.
The system can also be used as a normal search en-
gine. Left-clicking on a ﬁeld (e.g., the author ﬁeld)automatically runs a search for other documents as-
sociated with that person or ﬁeld. A full search formis also available to perform manual queries. Thesefeatures allow two-way dialog between user and
RA.
For example, in the example in Figure 1, one maynot care about the “News on-demand . . .” paper butmight want to know about other papers on news.Left-clicking on the subject ﬁeld brings up summa-ries for other documents with the same words in thetitle. These suggestions may then lead the user toperform a manual search, which in turn may lead tomore suggestions.
Different suggestion databases can be associated with
speciﬁc buffers or buffer types. For example, the sys-tem can be conﬁgured to automatically draw sug-
gestions from an e-mail archive when reading or writ-ing e-mail, and from the
INSPEC database whenever
writing a paper in the LaTeX formatting mode.These defaults are set by hand in a conﬁguration ﬁle.Databases can also be switched manually with a key-board shortcut. Database changes are sticky: If thedatabase is switched once for a particular buffer, thenrevisiting that buffer will automatically switch to thatdatabase thereafter.Figure 2    Emacs RA result screen
RHODES AND MAES IBM SYSTEMS JOURNAL, VOL 39, NOS 3&4, 2000 688
Authorized licensed use limited to: Georgia Institute of Technology. Downloaded on September 10,2020 at 15:52:31 UTC from IEEE Xplore.  Restrictions apply.  Margin Notes. Margin Notes2is a JITIR agent that
automatically rewrites Web pages as they are loaded,
adding hyperlinks to personal ﬁles. As a Web pageis loaded, Margin Notes adds a black margin stripto the right of the document. Like the
RA, it then
compares each section of the document to prein-dexed e-mail archives, notes ﬁles, and other text ﬁles,based on keyword co-occurrence. If one of these in-dexed ﬁles is found to be relevant to the current sec-tion of the Web page, a small “suggestion note” isincluded in the margin next to the relevant section.The note contains a quick description of the sug-gested text, a series of circles representing the rel-evance of the suggestion, and a link to obtain moreinformation. The suggestion note consists of a sub-ject, date, and author for the suggested text, thoughthe exact makeup of the note is customizable basedon the database.
Figure 3 shows a screen shot of a Web page on cel-
lular phone service plans, annotated by MarginNotes. This example is a page and annotation thatcame up during normal use of Margin Notes, thoughthe relevance of the annotation is better than thetypical annotation. The database used for this ex-ample is the collection of Media Lab e-mail archivessince 1988, a total of over 180000 messages. The sug-gested document, listed in the black margin to theright, is e-mail sent to the “hackers” mailing list andgives personal experiences with cellular service in the
MIT area. The circles at the top of a suggestion are
ﬁlled in with red to indicate the relevance of the sug-gestion.
Placing the mouse over a suggestion note produces
a list of the ﬁve keywords that were most importantin deciding the relevance of a suggestion to the an-notated Web page section (these are also shown inthe ﬁgure). Clicking on a suggestion note creates anew browser window that displays the full text of thee-mail, note ﬁle, or text being suggested. The sug-gested page also has feedback buttons used for eval-uating the system.
Because Web pages will often cover many different
subjects, Margin Notes segments the Web pages itannotates based on
HTML (HyperText Markup Lan-
guage) tags. Each section receives its own annota-tion, assuming the annotation is over a threshold rel-evance score. The exception is the ﬁrst annotationon each Web page, which is based on the entire pageinstead of a single section. This gives both a generalannotation as well as a speciﬁc, focused view. Mar-gin Notes uses the location of the annotation to in-dicate scope: annotations appear at the top of thesection to which they are relevant. Thus it is anal-ogous to marginal notes in traditional print. Theblack margin strip achieves “branding”; all text toFigure 3    Margin Notes screen shot
Choosing A Cell Phone Provider
Digital vs. Analog
What’s the difference?By J.A. Hitchcock
Are you considering getting a cell phone, but don’t know which provider to choose? Do you already
have a cell phone but want to switch providers?
It used to be fairly easy when it came to buying a cell phone–– you went to your local provider, took
advantage of their latest promotion (usually getting the phone for free with an annual contract), andthat was it. Today, not only do you need to decide whether you want an analog or digital phone orone that does both, you also need to pick the provider that can provide analog and/or digital service.''Re: cell phone
question''(rich)hackers–archiveMay 24, 1999
Keywords: cell
phone phone plancoverage
IBM SYSTEMS JOURNAL, VOL 39, NOS 3&4, 2000 RHODES AND MAES 689
Authorized licensed use limited to: Georgia Institute of Technology. Downloaded on September 10,2020 at 15:52:31 UTC from IEEE Xplore.  Restrictions apply.  the left of the margin is the page being annotated,
all text within the margin is placed there by MarginNotes.
Jimminy. Both the
RAand Margin Notes provide
potentially useful information based on a person’s
computational environment: his or her e-mail, doc-uments, Web pages being viewed, etc. Jimminy pro-vides information based on a person’s physical envi-ronment: his or her location, people in the room,time of day, and subject of conversation.
3Process-
ing is performed on a shoulder-mounted “wearablecomputer,” and suggestions are presented on a head-mounted display.
The ultimate goal is that all information about the
wearer’s physical environment will be available toJimminy through automatic sensors. However, thefocus of this research is not sensor technology butrather what can be done with that technology onceit is available. To this end, Jimminy is a general ar-chitecture that can use plug-ins for any sensor thatcan be attached to a wearable computer. Informa-tion that is not provided by sensors can be enteredinto the system by hand. The currently implementedsystem has been demonstrated with passive sensorsthat detect a person’s physical location, people in theroom, and the time of day. The general topic of aconversation is entered by hand in the form of real-time notes.
The hardware for the system is the “Lizzy” wearable
computer designed by Thad Starner,
4which consists
of a 100-MHz 486 processor running the Linux**operating system, a head-mounted display, and one-handed chording keyboard. The entire system ﬁts ina small shoulder bag. The display is the “PrivateEye**” made by Reﬂection Technology. Display res-olution is 720 3280 pixels, monochrome red with
one level of dimness. This display gives a crisp 80-column by 25-row screen with a virtual image seem-ing to ﬂoat in front of the wearer. The keyboard isthe “Twiddler**,” a one-handed keyboard made byHandykey Corporation that uses a 17-button system,on which multiple keys can be struck at once to ac-cess all the symbols possible on a normal keyboard,plus extra combinations for macros. Average typingspeed is about 35 words per minute using the Twid-dler, although Starner has been clocked at up to 60words per minute.
The wearable computer also includes several ways
to sense the outside world. When outdoors, a
GPS
is used to detect the wearer’s location. When indoors,a 418-MHz AMradio receiver detects unique radio
beacons that have been placed around the MediaLab.
5An alternate system uses IR(infrared light)
instead of radio, which gives a ﬁner control overwhere a beacon will be detected.
6Beacon numbers
are converted to room numbers via a static lookup.By putting these beacons into name badges, the wear-able can also detect who is currently in the same roomas the wearable user. This method is essentially iden-tical to the active badge system designed at Olivetti.
7
However, because people do not generally wearthese active badges, the people sensor is only usedfor demonstration purposes. The wearable computeralso has a 1.2-Mbit wireless network connection thatis used for communications and receiving informa-tion from sensors not directly attached to the com-puter. Sensors and Jimminy are interconnected us-ing Hive, a distributed agent architecture developedby Nelson Minar.
8
With recent improvements in sensor technology andin the processor speed of wearable computers, it isexpected that other types of sensing technology willsoon become available. One such technique is
ASR
(automatic speech recognition), which is now accu-rate enough so that information retrieval on a da-tabase of raw audio news stories can be performedwith over 55 percent precision.
9This percentage is
close to the level of performance that would beneeded to automatically generate queries for Jim-miny by transcribing a person’s natural conversa-tional speech. Another technique is vision-based au-tomatic face recognition,
10which could be used
instead of active badges to let the wearable knowwhat other people are in the room.
The wearable computer serves two main functions.
First, it is used as a general note-taking system. Inconversations and lectures, notes are usually touch-typed using the one-handed keyboard while main-taining eye contact with the person speaking. Thehead-mounted display is occasionally viewed to seewhat has just been typed. Any note written using thewearable computer can be tagged with peoplepresent, subject, location, and time stamp using asingle key combination. Over 850 notes have beentaken and annotated on the wearable computer bythis means over the course of four years. They rangefrom notes on classes and conversations at confer-ences to notes on dance steps. The second major useof the wearable computer is to retrieve notes andinformation anytime, anywhere. Reading and under-standing information on the head-mounted displayis a more attention-demanding task than note-tak-
RHODES AND MAES IBM SYSTEMS JOURNAL, VOL 39, NOS 3&4, 2000 690
Authorized licensed use limited to: Georgia Institute of Technology. Downloaded on September 10,2020 at 15:52:31 UTC from IEEE Xplore.  Restrictions apply.  ing. It is also more obvious to observers that the user
is distracted: the user’s eyes are clearly focused onthe screen, and it is difﬁcult to speak and read at thesame time. For these reasons information tends tobe looked up during pauses in conversation or in lec-ture situations.
The interface for Jimminy is based on the
RAbut
differs in a few important ways. First, screen real es-
tate is scarce for a wearable computer, so sugges-tions are presented in abbreviated form. Second, thefeatures of the environment that are currently be-ing sensed are listed on the mode line. Having thisinformation is important because sensor data maybe incorrect, and the user also needs a reminderabout what environmental information was last en-tered by hand so it can be updated. Third, keys aredeﬁned on the chording keyboard to increment ordecrement the bias on different ﬁeld types. For ex-ample, one could set biases so that the person ﬁeldis twice as important as other ﬁelds when ﬁnding use-ful documents. The biases are listed on the modeline as well. Finally, the system will modify the biasfor certain features based on recent-modiﬁcationtimes. For example, if the wearer of the system en-ters a new room, the bias for room location is tem-porarily increased by three. After a minute in thesame room, the bias is returned to base-line levels.Figure 4 shows a screen shot of Jimminy as it wouldappear on the head-mounted display. The top 80 per-cent of the screen is reserved for notes being enteredor read, plus the standard Emacs mode line givingtime and information about the ﬁle being edited. Thenext four lines show suggestions based on the wear-er’s current context. The display is the same as the
RAexcept formatted for the 80-column monochrome
display. The bottom mode line shows a condensedview of current biases for location, subject, person,and current text being typed, followed by the con-text currently being used. The actual head-mounteddisplay is bright red on black with 720 3240 pixel
resolution, with the number of characters and theaspect ratio shown in the ﬁgure.
For the example scenario of Figure 4, imagine the
wearer is talking with David Mizell, a fellow “wear-ables” researcher from Boeing, and has just enteredMedia Laboratory room E15-335, which is where theautomatic embroidery machine used in one of theresearch projects is kept. This example is hypothet-ical, although the screen shot is of the actual systemusing the real database of notes written on the wear-able. The mode line shows the current location andpeople in the wearer’s environment and shows thatthe bias for location and people present is four, andthe bias for subject and current text being typed areFigure 4    Jimminy screen shot
IBM SYSTEMS JOURNAL, VOL 39, NOS 3&4, 2000 RHODES AND MAES 691
Authorized licensed use limited to: Georgia Institute of Technology. Downloaded on September 10,2020 at 15:52:31 UTC from IEEE Xplore.  Restrictions apply.  both one. The periods around the location and per-
son biases indicate that they have temporarily beenraised because these features changed recently. Inone minute it will go back to the hand-set value ofone. Biases can also be set using the chord keyboard.The ﬁrst suggestion “embroidery machine class” isa note that was taken during the training class forthe embroidery machine. As can be seen in the key-words section (far right), the suggestion is basedmainly on the room number, but also on some ofthe words in the notes being typed. The second andthird notes are about David Mizell, the ﬁrst beinghis entry in the wearer’s contact Rolodex** ﬁle andthe other being notes about his talk on augmentedreality at a conference in 1998. The ﬁnal suggestionis an e-mail note about the wearable fashion showfor which the conductive cloth technology was be-ing developed at the Media Lab, based on keywordsthat have been typed into the notes area.
Savant. All three implemented
JITIR agents use the
same back-end system, called Savant. The front end
senses the environment (that is, the document ore-mail being written, the Web page being viewed, orthe physical environment of the user of a wearablecomputer) and sends that information in text formto Savant as a “query.” Savant then works as an in-formation retrieval engine: given a query, it producesa rank-ordered list of preindexed documents thatbest match the query. Savant consists of two pro-grams: ra-retrieve performs information retrieval
based on a query, and ra-index creates index ﬁles so
retrieval can be performed quickly. Indexes can becreated from generally useful sources such as a col-lection of newspaper or journal articles, organization-wide collections such as ofﬁce memos, or from per-sonal sources such as e-mail and notes. Previousversions also allowed pages to be indexed directlyfrom the Web. Documents are usually reindexednightly to incorporate new changes and additions.
The power of Savant comes from a strong template-
matching system that can recognize documents, parseout ﬁelds, and index them all automatically. For ex-ample, if pointed at a top-level directory of heter-ogeneous ﬁles, it will recognize and parse e-mail ar-chives,
HTML ﬁles, LaTeX ﬁles, notes taken on the
wearable computer, paper abstracts from the INSPEC
database, and raw text, while ignoring other ﬁle for-mats. It will also break e-mail archives into individ-ual messages. This means indexing can be performedcompletely automatically with no hand annotation.Different ﬁelds from documents are identiﬁed andindexed separately. For example, the from ﬁelds ofe-mail archives are indexed as people, whereas the
title ﬁelds of
HTML documents and the subject ﬁelds
of e-mail messages are indexed as subjects. Differ-
ent ﬁeld types can have different similarity metrics.For example, a collaborator at British Telecom hasdeveloped a version of the
RAthat can ﬁnd docu-
ments that are related to a current location basedon
GPS coordinates.11If a document is similar to a
person’s current context based on more than oneﬁeld (e.g., if both the “from” ﬁeld and body of a mes-sage partially match), a linear combination of thesimilarities are used based on weights deﬁned in thetemplates. The template system is also used for que-ries, so ﬁelds can be parsed out of e-mail being writ-ten or Web pages being read. Templates are hard-coded into Savant, but are designed to be easilymodiﬁed or added with a recompilation of the sourcecode.
Automatically generated queries tend to contain ex-
traneous text, such as signature lines and e-mailheaders, that is not useful for retrieval. Indexed doc-uments will likewise have
HTML markup and head-
ers that will dilute the value of important data whenselecting documents. To address this problem, eachtemplate can associate a ﬁlter bank with each ﬁeld.A ﬁlter bank is an ordered list of Perl-style regularexpressions that match text that should be removedfrom the ﬁeld before parsing. For example, ﬁltersassociated with the e-mail body ﬁeld recognize and
remove e-mail signature lines, headers from includedﬁles, and common lines such as “Begin forwardedmessage.” Filters associated with the e-mail person
ﬁeld remove all information except for the username, and ﬁlters associated with all ﬁelds in
HTML
documents remove hypertext tags and comments.
Although Savant can simultaneously use different
similarity metrics for different ﬁelds, the most com-mon metric is for similarity between two texts. Theparticular algorithm used is the Okapi version of theTerm Frequency/Inverse Document Frequency(
TF/iDF ) algorithm, a fairly standard benchmark text
retrieval algorithm.12
Theoretical issues
There are three primary questions being addressed
by this research, ranging from the ﬁelds of psychol-ogy and decision sciences to document retrieval tointerface design and cognitive science. An overviewof the issues surrounding these questions is presentedbelow. For a full discussion, interested readers arereferred to the dissertation by Rhodes.
13
RHODES AND MAES IBM SYSTEMS JOURNAL, VOL 39, NOS 3&4, 2000 692
Authorized licensed use limited to: Georgia Institute of Technology. Downloaded on September 10,2020 at 15:52:31 UTC from IEEE Xplore.  Restrictions apply.  How does the use of a JITIR agent affect the way in
which a person uses information? Imagine an ex-
tremely paranoid executive who wants to be sure hereads every piece of information related to his work.To make sure he does not miss anything, he searcheshis old e-mails and ofﬁce memos after every para-graph he writes. This would imitate the effect of a
JITIR agent. In fact, it would be better than a JITIR
agent because he could perform his searches moreprecisely than could any automated process.
Of course, no one is as meticulous as the executive
described. Sometimes a person wants a particularpiece of information, and in this case a search en-gine is the appropriate tool. Other times a personwill not bother to perform a search because of a lackof time, because the information he or she alreadyhas is “good enough,” or because the person expectsa search will not turn up anything useful.
Such action (or inaction) is in keeping with Zipf’s
Principle of Least Effort ,
14which states that people
will try to minimize their total future work, given their
best estimates at the time. Payne, Bettman, and John-
son expand on this principle, arguing that peoplechoose decision-making strategies based on multi-ple goals, including goals of accuracy and the con-servation of limited cognitive responses.
15This
framework is based on anticipated accuracy versusanticipated effort: a decision maker assesses the ben-eﬁts and costs of available strategies and chooses thestrategy with the best cost/beneﬁt trade-off. The ef-fort-accuracy framework has been used to explainwhy people behave differently using different kindsof information displays in a computational environ-ment.
16It can also be used to explain why people
make different purchases depending on whether per-unit prices in a grocery store are listed on a singlesign or only listed under each product.
17
Studies in computer response time indicate that smallincreases in the effort required to perform a task canhave large effects on whether a person will botheracting at all. For example, Robert Miller argues thatfor many tasks, more than two seconds of responsedelay is unacceptable and will result in fewer usesof a particular tool, even at the cost of decreasedaccuracy.
18He also argues that there is not a linear
decrease in efﬁciency as response delay increases;there are response delay thresholds beyond whichsudden drops in mental efﬁciency will occur. Milleris primarily discussing system response delays, but
the same short-term memory limitations he discussesalso apply to performing subtasks that distract froma primary task. For example, when performing asearch for information about a digression, a personneeds to use short-term memory to keep his or herplace in the larger framework of the task. Theamount of short-term memory required, and thusthe amount of effort required in the task, will de-pend on a number of factors including the complex-ity of the digression, the amount of time requiredto complete the task, and the similarity of the digres-sion to the primary task.
When applied to the information search domain,
these theories suggest that if the cost of ﬁnding and
using information is more than the expected value
of that information, then the search will not be per-formed. This result could be the case for several rea-sons. First, the desired information may not be im-portant enough. For example, the searcher mightthink he or she “remembers it well enough,” or theremight be little reward for accuracy. The person mightalso think a search will not be fruitful, and thus theexpected value is low even if an unexpectedly goodresult would be worthwhile. Finally, the person couldbe under time pressure or dealing with a poor searchinterface, and thus the effort required for a searchis too costly.
JITIR agents greatly reduce the cost of searching for
information by doing most of the work automatically.The downside is that queries are automatically gen-erated and therefore will not be as exact as woulda human-generated query. This low-cost search ismore than just a time-saver, it has the qualitative ef-fect of providing information in situations where anindividual is not personally willing to perform asearch. In terms of an effort-accuracy trade-off, a
JITIR agent is a resource for retrieving information
that would otherwise be too costly to search for orwhere a search by other means has a low expectedbeneﬁt.
IBM SYSTEMS JOURNAL, VOL 39, NOS 3&4, 2000 RHODES AND MAES 693JITR agents greatly reduce
the cost of searching
for information
by doing most of the work
automatically.
Authorized licensed use limited to: Georgia Institute of Technology. Downloaded on September 10,2020 at 15:52:31 UTC from IEEE Xplore.  Restrictions apply.  How can a JITIR agent automatically ﬁnd informa-
tion that would be useful to a person by looking atthat person’s current environment? The perfect re-
trieval engine for a
JITIR agent would instantly be
able to know whether a piece of information wouldbe useful to a person. The next best thing would bean engine that could know a person’s task, what in-formation he or she already knows, the thoughts heor she is currently thinking, and how he or she pro-cesses new information. With such information, anagent could easily deduce whether informationwould be useful. Unfortunately, we have neither theability to prognosticate nor read minds. An agentmust “make do” with whatever limited informationit can sense automatically from a person’s compu-tational or physical environment.
Because it is impossible to directly sense whether a
document will be useful or not, features of the envi-ronment that are detectable must be used as pre-dictors, or proxies for usefulness. For the
JITIR agents
presented here, the similarity of a document to the
person’s current local context is used as the proxyfor usefulness. The more similar it is, the more use-ful it is likely to be.
Although Savant is designed to use many similarity
metrics, the implemented systems all rely heavily ontext-retrieval techniques. The retrieval problems for
JITIR agents differ from traditional text retrieval as
described in the following subsections.
Lack of priors. A person chooses information re-
sources based on certain needs at the time. For ex-
ample, if a doctor needs a medical reference, he orshe will use the National Institutes of Health searchsite. If the doctor wants to know where to play golf,he or she will browse the tourism board database.The choice of information source is one of the bestindications of a person’s current needs. In terms ofprobability, the fact that a person chose a particulardatabase gives a strong prior (bias in probability) thatinformation in that database will be useful. Usually
JITIR agents do not have such a direct indication of
what information might be valuable. Although onecould access a combined database of all informationthat might be valuable, this solution neither scalesnor retrieves quality documents.
Of course, some priors exist even with
JITIR agents.
The kinds of information that can be provided by an
agent will be implicitly constrained by its interface,the sensors it uses, and the people who use it. Forexample, an agent embedded in a word processorcan be expected to provide information that mightbe related to anything typed in that application, butnot in other applications. This constraint providessome natural limits on the kinds of tasks being per-formed, though usually not as many as are enjoyedby a specialized search engine. It is also sometimespossible to use features of the task environment tomake a good ﬁrst guess at the kind of informationthat might be most useful. For example, the
RAuses
the Emacs editing mode to tell whether a person isreading e-mail, writing code, or writing a paper. Thisinformation is used to choose between archivede-mail, a code library, or paper abstracts from the
INSPEC database.
Multiple topics. In a manual information system a per-
son usually searches for one piece of information ata time. A person’s environment will usually relateto several different subjects. For example, the dis-cussion in this paper ranges from information re-trieval to interface design to speciﬁc implementationsof
JITIR agents. E-mail will often cover even more
disparate topics within the same message.
Sometimes multiple-subject queries can be an ad-
vantage. Any documents that match more than oneof the subjects (e.g., in this case relating to both in-formation retrieval and interface design) are likelyto be useful documents, and documents relating tojust one subject represented in a query might still beuseful. However, multiple-subject queries can alsocause traditional
IRtechniques to miss documents
that are very relevant to one particular subject in fa-vor of documents only somewhat relevant to all sub-jects represented. Furthermore, parts of the querymight not be useful to a retrieval engine at all. Forexample, a signature line at the bottom of an e-mailmay not contain any information relevant to a per-son’s current task or interests. This information musttherefore be removed or otherwise ignored.
Different criteria for evaluation. In the text-retrieval
ﬁeld, algorithms are typically evaluated based on
whether the documents returned are relevant to thegiven query. It is assumed that the query is a goodindication of the user’s interests.
JITIR agent que-
ries are automatically created, so relevance is notgood enough. To evaluate the information retrievalalgorithm of a
JITIR agent, one needs to show that
the hits returned are useful to a person given a cur-rent task. Although relevance may correlate with use-fulness, the two are not the same. For example, acitation from the
INSPEC database could be relevant
to a paper a researcher is writing but still be useless
RHODES AND MAES IBM SYSTEMS JOURNAL, VOL 39, NOS 3&4, 2000 694
Authorized licensed use limited to: Georgia Institute of Technology. Downloaded on September 10,2020 at 15:52:31 UTC from IEEE Xplore.  Restrictions apply.  if the suggested document is already known. Al-
though relevance can be evaluated given only aquery, usefulness must be evaluated for a given per-son in a given task environment. This requirementmakes it more difﬁcult to generalize results.
Queries are longer. In the past ﬁve years the
IRﬁeld
has been attempting to produce relevant documents
based on shorter queries. This trend has been spurredby the needs of Web search engines, where the av-erage query length is less than three words.
19Many
of the techniques developed have been ways to per-form query expansion, where a short query is auto-matically augmented with words appearing in thebest ranked documents of an initial probe search.
20
With JITIR agents, the environment provides a large
amount of data that can potentially be a part of aquery, so query expansion is less important.
Both indexed documents and queries are multivariate.
Both documents being suggested and queries them-selves will often contain people’s names, dates, sub-jects, abstracts, locations, phone numbers, and a hostof other information types. Although manual que-ries can also contain such information, they are of-ten sparser because of the difﬁculties of enteringlarge amounts of data.
JITIR agents need both ranked-best evaluation and ﬁl-
tering. Search engines normally produce a ranked-
best list of hits for a given query. The absolute rel-evance score of a hit is not important as long as thisrelative ranking is correct.
JITIR agents require a com-
bination of ranked-best evaluation and ﬁltering. Theyneed to display the top few hits, but also need to dis-play an absolute conﬁdence in the relevance of a sug-gestion and to potentially suppress the display of low-quality suggestions. This need is similar to theproblem faced by text-ﬁltering systems such as au-tomatic newspaper-clipping services. However, thesesystems assume that a stream of documents is com-pared to a long-lasting set of query proﬁles, such asa list of keywords expressing user interests.
21The
queries in JITIR agents are not long-lasting, so most
of the machine-learning techniques used by thesetext-ﬁltering systems cannot be applied.
High precision is required. Information retrieval re-
searchers often talk about the trade-off between pre-
cision (making sure all suggested documents are ofhigh relevance) and recall (making sure all relevantdocuments are suggested). Because
JITIR agents
largely play a supporting rather than a primary taskrole, they usually should not suggest more than a fewdocuments. More suggestions, even if all of them
were relevant, would be too much of a distraction.For this reason, the information retrieval algorithmsfor
JITIR agents should tend to favor precision over
recall.
How should a JITIR agent present potentially use-
ful information? The most important design con-
straint for JITIR agents is that reading provided in-
formation should be a secondary task. Unlike usersof a search engine,
JITIR agent users are not actively
seeking information being suggested. They are lesstolerant of distraction from their primary task andare less willing to dig through suggestions to ﬁnd use-ful information. Furthermore, even if a suggestedtext is highly relevant to a user’s current context, theperson may not be interested in it. The text couldalready be known, the user may not wish to be dis-tracted, or may simply not want any new informa-tion. For this reason an interface must have a lowcost for false positives. It must be an ignorable
interface, although not so ignorable that it is neverused.
The design of an ignorable interface must take into
account two limitations on cognitive processes: fo-
cused attention anddivided attention. Focused atten-
tion is the ability to attend to intended stimuli andtasks while ignoring others. The other side of the coinisdivided attention: the ability to switch between tasks
or stimuli. Generally speaking, it is easier to focusone’s attention when the features of the environmentbeing attended are dissimilar to distractions.
22For
example, it is easy to listen to talk radio while driv-ing because driving is largely visual and spatial,whereas listening to the radio is auditory and ver-bal.
Unfortunately, there is a trade-off between focused
and divided attention: the same similarity in displaythat makes it harder to focus on one stimulus andignore the other makes it easier to switch focus be-tween two stimuli. This trade-off leads to the prox-
imity compatibility principle, which states that high
display proximity (similarity) helps in tasks with sim-ilar mental proximity, and where information is re-lated and needs to be treated together.
23For exam-
ple, military pilots use head-up displays to placeannotations visually on top of enemy and friendlyaircraft. This use of spatial proximity helps link theannotation to the object but can make it more dif-ﬁcult to process only one without the other.
IBM SYSTEMS JOURNAL, VOL 39, NOS 3&4, 2000 RHODES AND MAES 695
Authorized licensed use limited to: Georgia Institute of Technology. Downloaded on September 10,2020 at 15:52:31 UTC from IEEE Xplore.  Restrictions apply.  Divided attention is also easier when switching be-
tween tasks because it does not require a large shiftin the contents of short-term memory. This situa-tion is obviously the case when one of the tasks haslow memory requirements. For example, turning ona light while talking on the phone requires little shift-ing of memory because the location of the light switchcan be seen: it is knowledge in the world. However,
ﬁnding an object or reading e-mail while on the
phone requires more swapping of short-term mem-ory between tasks, and the phone conversation willprobably suffer. Short-term memory also requiresless swapping if the two tasks share similar mentalmodels, or schema. For example, several schema willbe shared by tasks that relate to the same generaltask or subject.
24
JITIR agents need to allow persons to focus their at-
tention on their primary task, and also to divide theirattention between the primary task and the infor-mation provided by the agent.
To make focused attention easier, a
JITIR agent
should use different modalities or channels than are
used by a person’s primary task. Such use is espe-cially important when the primary task is demand-ing. For example, Jimminy is designed to give infor-mation to persons as they engage in conversation orlisten to lectures. In these environments the audi-tory modality is primary, so Jimminy uses a visualdisplay for output.
It is also important that suggested information is not
linked to parts of the environment to which it is notrelevant. For example, if an agent is giving informa-tion related to a text editor, the display should notbe near the Web browser, nor should it have a colorscheme or layout that associates it with the Webbrowser. Doing so would encourage checking the
JITIR agent output at times when the suggestions are
almost guaranteed not to be related to the currenttask.On a related note, it is important to be able to dis-
tinguish a suggestion from the environment. For ex-ample, it must be clear that a suggestion on a Webpage comes from Margin Notes and is not actuallya part of the original Web page being viewed. Onemethod is to ensure that suggestions appear out-of-band, for example, in a separate window or differ-ent modality. Another method is to ensure that sug-gestions look nothing like the user’s other context.For example, annotations in an augmented realitysystem are never mistaken for the real world becausethe resolution of computer graphics is not yet highenough. The third method is branding: ensuring thatannotations have a unique “look and feel” that setsthem apart. For example, annotations could use adifferent font, color, location, or modality than theinformation being annotated.
To make divided attention (task switching) easier,
a
JITIR agent should display information in a way that
is congruous with the parts of the environment towhich it relates. For example, it is likely easier tolook at suggestions from an e-mail archive whenreading or writing e-mail because the two formatshave the same mental model. Similar mappings be-tween suggestion and the context to which it is rel-evant can be achieved with color and font. Probablythe most effective way to link information is to usespatial proximity: put information near what it isabout. In the Remembrance Agent, the suggestiondisplay is in a buffer within the editor window ratherthan a separate window. This placement links the
RAwith the particular text being edited and keeps
it from being linked with other applications runningon the desktop. In Margin Notes, annotations ap-pear to the right of the paragraph or section to whichthey relate. Moving the scroll bar in the Web browsermoves the annotations as well, increasing the men-
tal linkage between the two.
The Margin Notes example reveals another use of
spatial proximity: It can indicate to which part of auser’s context a suggestion is relevant. Even if a per-son’s full context is constrained to a single Web page,it should still be apparent whether a suggestion isrelevant to a single paragraph, a section, or the en-tire Web page. Spatial proximity is a good way toindicate this information, although when this is notpossible, the indication can still be by ﬁat, e.g., bydeclaring that suggestions are chosen based on rel-evance to the whole body, or by indicating the scopeof relevance in the suggestion in some other way.
RHODES AND MAES IBM SYSTEMS JOURNAL, VOL 39, NOS 3&4, 2000 696It is import ant
to be ab le to dist inguish
a suggestion
from the environment.
Authorized licensed use limited to: Georgia Institute of Technology. Downloaded on September 10,2020 at 15:52:31 UTC from IEEE Xplore.  Restrictions apply.  Even when the interface is designed to help divided
attention, a JITIR agent will still increase cognitive
load. When the information provided is valuable, thetrade-off is worthwhile, but false positives will stillbe a problem. False positives are also guaranteed:a
JITIR agent will never reach 100 percent useful in-
formation without perfect information about a per-son’s mental state. Given this limitation, informa-tion should be displayed to minimize the cognitiveand perceptual load the user must undertake to eval-uate the quality of information provided.
One display technique is what we call a “ramping
interface,” where information is conveyed in stages.Each stage of a ramping interface provides a littlemore information, at the cost of a little more atten-tion required to read and understand it. The idea isto present useful information, while at the same timeallowing a person to detect bad information and bailout as early as possible.
In a ramping interface the user should always be able
to obtain more information by going to the next stage,and the action required to get to that stage shouldbe proportional to the amount of information pro-vided in the current stage. It should only require asimple action such as reading a pop-up window fora user to go to early stages. Later stages might re-quire the user to click on an icon, trading off sim-plicity for increased control of what information isdisplayed. Note that stages are not deﬁned by dis-play actions taken by the agent, but rather are de-ﬁned as pieces of information that can be individ-ually processed by a user. For example, a Web pagewith a large-font title, keywords in boldface, and thenthe body of the page would contain three stages evenif the page is rendered all at once, because a readercan easily process each chunk of information sep-arately and use that information to decide whetherto read further.
Of the three implemented
JITIR agents, Margin
Notes best illustrates the idea of a ramping inter-
face.
The ﬁrst stage could be referred to as the no-action,
no-information stage. In this stage the system an-alyzes a section of a Web page and decides whetherto leave any suggestion at all. There are several rea-sons a section might not be annotated. First, the bestsuggestions may still be below the required relevancethreshold. The section may also be too small to an-notate, or the document as a whole might be toosmall. At this ﬁrst stage, the input is simply a passivesensor watching the user’s actions. No user actionor attention is required to show the agent what todo. The output at this stage is potentially nothing:the agent simply passes the
HTML to the browser and
continues.
When Margin Notes determines that a suggestion
is above a certain relevance threshold, it automat-ically jumps to the second stage and shows a sug-gestion note. In keeping with the philosophy thatjumping to the next stage should be commensuratewith the amount of work or attention required bythe current stage, no user thought or action is re-quired to display the suggestion note.
At this point the user may ignore the suggestion en-
tirely, and the interaction has cost nothing more thansome screen real estate and a very minor cognitiveload. If the user wishes to go to the next stage, heor she can quickly view a row of ﬁlled-in circles in-dicating the relevance value for that suggestion.
The next stage is reached by reading the suggestion
description, which requires further attention on thepart of the user. Information in the suggestion noteis as concise as possible to allow rapid scanning forcontent. The box also contains many different kindsof information to try to contextualize the suggestion.For example, when e-mail is displayed, the box con-tains subject, author, date, and archive ﬁle name inthe hope that at least one of these will be a goodindication of what the suggestion is about.
At the fourth stage of Margin Notes the system dis-
plays the most relevant keywords. Going to this stagerequires physical action by the user (a mouse-over),and gives an incremental increase in the amount ofinformation returned. While keyword informationcould have been included in the original suggestion(reducing the system to a four-stage ramping inter-face), it was decided that this information made thesuggestion note too cluttered. To jump to the ﬁnalstage, the user clicks on the link and obtains the fullysuggested text. At this point the user is completelycommitted to seeing the text and has been distractedfrom the primary task. It is hoped that if the userarrives at this point, the suggested text is worth theattention spent.
Note that the actions required to go through the
stages of the Margin Notes ramping interface in or-der are also the natural actions to obtain more in-formation in the context of Web browsing. The usersees a link, reads it, moves the mouse to the link,
IBM SYSTEMS JOURNAL, VOL 39, NOS 3&4, 2000 RHODES AND MAES 697
Authorized licensed use limited to: Georgia Institute of Technology. Downloaded on September 10,2020 at 15:52:31 UTC from IEEE Xplore.  Restrictions apply.  and clicks. This action sequence allows the user to
jump to the full suggestion quickly, while still seeingall stages.
When designing a ramping interface, it is also help-
ful to consider at what stage a user is likely to re-ceive the information needed. In the Margin Notessystem, it is assumed that most of the time users willreceive information from the full suggested text, butthat occasionally they will be reminded by the sug-gestion note itself and never need to follow the link.In contrast, a
JITIR agent intended for an automo-
bile or other attention-demanding environmentmight be designed such that users normally need notgo past the ﬁrst stage of a suggestion.
Evaluations
Two user studies have been performed. The ﬁrst is
a controlled-task experiment that compares the use-fulness of
JITIR agents to a traditional search engine.
The second study evaluates the information retrievalused by the implemented
JITIR agents. It also exam-
ines how the database used by an RAaffects the qual-
ity of suggestion. These systems have also been de-ployed for several years, and user feedback has beenused to improve the systems.
Controlled task evaluation. The ﬁrst experiment
compares
JITIR agents to nonproactive information
tools such as search engines. Twenty-seven subjects
were recruited from the MIT community and were
divided randomly into experimental and controlgroups. Subjects from both groups were asked towrite a newspaper-style article about housing at
MIT,
currently a hotly debated topic around campus. Con-trol group users were given a normal Emacs text ed-itor and a Web browser accessing the
MITTech news-
paper search page.25Experimental group subjects
were given an Emacs augmented by the Remem-brance Agent and the
MIT Tech search page aug-
mented by Margin Notes. The Emacs RA, Margin
Notes, and The Tech search page all pulled from the
same archive of 16240 news articles. All interactionswith the information tools were logged, and subjectswere also given pre- and post-task surveys.
A control group of 14 and an experimental group
of 13 subjects were tested. Of these, two outliers fromthe control group viewed a number of articles morethan 1.5 times the inner-quartile distance from thethird quartile and were eliminated. One of these tworeported that he had ﬁnished early and browsed The
Tech about other issues for the remaining time, theother reported she had little knowledge about hous-ing and so wrote about “what The Tech says about
housing.” Results were consistently good for the
RA
in terms of preference and usage. Margin Notes,however, did poorly in both categories. This outcomeis not unexpected, since Margin Notes was never dis-playing information when the subjects were perform-ing their primary task. Within the setup of this ex-periment, the amount a subject used the searchengine set an upper bound to how many articleswould even be displayed using Margin Notes.
Subjects who were given all three tools showed a con-
sistent preference for the
RAover the search engine
and the search engine over Margin Notes in termsof ranking, overall usefulness, and whether theywould want the tool for a similar task. As can be seenin Table 1, 78.5 percent of experimental subjectsranked the
RAas their number one choice. (Because
some answers were left blank, percentages do notadd up to 100 percent.) The
RAwas also rated around
a point (out of seven) higher than the search enginefor both usefulness and if the subject would want touse the system for a similar task. Margin Notes, incontrast, was consistently rated lower than the othertwo systems. The differences between the
RAand the
rank order of the search engine and whether the sys-tem was useful are both statistically signiﬁcant (p 5
0.05); the differences between the search engine andMargin Notes and the differences in whether the sub-ject would want to use the system again are not sig-niﬁcant. Errors are to the p 50.05 level.
The usage patterns for the different tools point tosimilar conclusions. As can be seen from Table 2,subjects from the experimental group viewed aroundthree times as many different Tech articles as did
those in the control group, and within the experi-mental group subjects viewed around two-and-a-halftimes as many articles using the
RAas they did using
the search engine. The difference between total pagesviewed in the two groups and the differences betweensearch engine and
RAuse within the experimental
group are signiﬁcant to the 0.01 level. Less than one-third of the experimental subjects viewed any doc-uments suggested by Margin Notes at all, and eventhose did not view many.
The essays themselves were also examined and coded
to see whether a difference could be found betweenthe control and experimental groups. Articles wereblinded and coded for number of facts mentioned,number of references to The Tech, and overall qual-
ity. However, individual variance was high, and no
RHODES AND MAES IBM SYSTEMS JOURNAL, VOL 39, NOS 3&4, 2000 698
Authorized licensed use limited to: Georgia Institute of Technology. Downloaded on September 10,2020 at 15:52:31 UTC from IEEE Xplore.  Restrictions apply.  statistically signiﬁcant difference was found between
the two groups.
From these results it is clear that the RAis not just
an alternative for a search engine; rather it facili-
tates the retrieval of information that would not oth-erwise be viewed at all. This conclusion is supportedby the fact that search engine use was not signiﬁ-cantly reduced when users were given the
RA, and
the total number of articles viewed increased. Thisfact follows directly from the accuracy versus efforttrade-off described earlier. As one subject com-mented, “the hits [from the
RA] weren’t as effective
or relevant as the ones from the search engine, butI would never bother using the search engine.” Twoother experimental subjects commented that they“would be writing opinions, and the
RAwould bring
up the facts to support those opinions automatical-ly.” This comment is in contrast to a subject in thecontrol group, who complained that he bothered tocheck his facts with the search engine, but it was agreat deal of effort, and he almost did not bother.Perhaps the best review of the
RAwas a subject who
commented that it was “almost an unfair advantageto have the
RA.”
A few criticisms were made about the RAthat could
easily be remedied. First, several subjects commentedthat they would start receiving very good suggestions,but that the display would “settle” and show the samesuggestions after a few paragraphs had been writ-ten. This situation occurred because the
RAwas set
up with only one scope, based on the past 500 wordsof the text being written. As described earlier, the
RAis conﬁgurable for multiple scopes, each describ-
ing a different database or based on a differentamount of text. It would have been simple to con-ﬁgure the
RAso a third of the suggestions were based
on the past 20 words being written, a third based onthe past 100 words, and a third based on the past500 words written. However, this particular exper-iment only used the one scope.
Several subjects also requested the ability to high-
light a particular region or word for which theywanted more information. While the
RAdoes not
have this feature yet, it does have the capability toperform full manual queries based on individualstrings. However, subjects were not informed aboutthis feature because the experiment was designed toexamine the proactive nature of the
RA. The high-
lighting feature will be added in a future release.Information retrieval test. A second experiment was
performed explicitly to test the query-free informa-
tion retrieval system used by the RA, Margin Notes,
and Jimminy. Media Lab researchers were asked tosubmit conference papers and articles that they hadconverted to
HTML and placed on the Web. These
papers were annotated using Margin Notes, runningwith a database containing a subset of the
INSPEC
collection of abstracts and citations. The databasecontained 152860 citations that had been pickedbased on
IEEE thesaurus labels that matched MITMe-
dia Lab areas of research (e.g., “user interfaces,”“computer vision,” etc.). Margin Notes was patchedto display all annotations regardless of relevance, andthe relevance score was blanked out. The research-ers were then asked to rate each annotation in termsof relevance to their paper in general, relevance tothe section it annotates, and whether the citationwould be useful if they were writing or rereading theirpaper. Nine researchers were asked to evaluate theannotations on their papers, for a total of 112 spe-ciﬁc annotations.
Generally, the annotations were rated highly for rel-
evance. As can be seen in Table 3, the average scorewas 3.3 out of 5 for relevance to the paper in generaland 3.4 out of 5 for relevance to a speciﬁc section.In all, 7 69 percent of the annotations received a
score of four or ﬁve for general relevance, and 4 69
percent for relevance to a speciﬁc section (p 50.05).Table 1 Experimental group reported preferences (n 513)
Search
EngineEmacs
RAMargin
Notes
Found useful (1–7) 3.8 61.3 5.1 60.7 2.8 61.1
Would want again (1–7) 4.8 61.1 6.0 60.8 3.9 61.2
Percent ranked #1 27 78.5 9
Percent ranked #2 64 15 9Percent ranked #3 9 8 82
Table 2 Number of unique Tech articles viewed (n 512,
n513)
Total Search
EngineEmacs
RAMargin
Notes
Control mean 2.8 61.7 2.8 61.7
Control median 2 2Experimental
mean7.362.4 1.9 61.0 4.9 61.9 0.5 60.5
Experimental
median8260
IBM SYSTEMS JOURNAL, VOL 39, NOS 3&4, 2000 RHODES AND MAES 699
Authorized licensed use limited to: Georgia Institute of Technology. Downloaded on September 10,2020 at 15:52:31 UTC from IEEE Xplore.  Restrictions apply.  Usefulness scores were not as good as relevance
scores. The average usefulness score was only 2.7,with 35 percent of the annotations receivin ga4o r
5. With a further look at the data, it is clear that, atleast for this task, relevance was a necessary but notsufﬁcient condition for usefulness. Of particular in-terest is that, of the 4 67 percent of citations that
were rated low on usefulness (1 or 2) but high ongeneral relevance (4 or 5), 100 percent were notedas being not useful because the citation was alreadyknown by the person doing the rating. Moreover, 68percent were not only known, but were in fact writ-ten by the person doing the rating. This result is en-couraging for three reasons. First, it indicates thathigher usefulness ratings could be obtained by us-ing a small amount of domain knowledge to avoidsuggesting references that the user most likely al-ready knows. For example, in this case the systemcould avoid listing citations that are already refer-enced in the paper or written by the user of the sys-tem. Second, the fact that these references were rel-evant but already known by the author of the paperbeing annotated means the annotations would prob-ably be useful to someone less well-versed in the par-ticular subject. Third, just because a reference is al-ready known does not mean it is not useful. Someof the readers rated known annotations as still be-ing useful, commenting that they were a good re-minder.
Because the relevance score is used both as an in-
dication of usefulness and for ﬁltering low-relevancesuggestions, it was hoped that the score would havea strong correlation to how relevant a person wouldﬁnd an annotation. Two relevance scores were tested.The ﬁrst is normalized by the number of uniquewords in the query (the section being annotated).When this normalization is not performed, relevancescores for long queries can be orders of magnitudehigher than scores for short queries. The second wasthe raw unnormalized score. Unfortunately, the non-normalized score had only a low correlation to hu-man judgments of relevance (r 50.36, p 50.0002),
accounting for only 13 percent of the variation. Nor-malized scores were even lower (r 50.13) and were
not statistically signiﬁcant. The reason is query lengthcorrelates to relevance (r 50.27, p 50.05), because
with more words in the query, the text-retrieval sys-tem can ﬁnd a better match. Correlations betweenscores and usefulness were not signiﬁcant, presum-ably because highly relevant annotations were morelikely to already be known by a reader and thus notbe useful.
Related work
Most directly related to this work are other
JITIR
agents: systems that proactively provide information
based on a person’s local context in a nonintrusiveyet accessible manner. Several such systems are de-scribed below.
Watson
26is a system that automatically produces and
submits AltaVista** or other Web queries based on
a user’s current Web page or Microsoft Word** doc-ument. Results are clustered and displayed in a sep-arate window. Watson is designed both to proactivelydisplay information and to augment queries to Webpages with local context. It also includes domain-spe-ciﬁc features, such as automatically searching the Ar-riba Vista image search engine whenever a MicrosoftWord user creates an image caption.
SUITOR27watches a person’s Web browser, word pro-
cessor, and other applications and provides poten-tially useful information above the task bar at thebottom of the screen. It is based on a blackboardarchitecture with multiple agents, each looking fordomain-speciﬁc information. For example, if a per-son is looking at the
IBMWeb page and also looking
at ﬁnancial pages, SUITOR will present IBM stock
quotes at regular intervals.
Letizia28automatically recommends Web pages a
person might want to visit, based on a short-term user
proﬁle and the Web page currently being viewed.Letizia automatically creates a user proﬁle by com-piling keywords contained in previous pages viewedby the user. It then acts as an “advance scout,” fol-lowing links from the user’s current Web page andbringing up pages that match the user’s proﬁle. Inmost
JITIR agents the source of suggested informa-
tion is personalized and static (though slowly updat-ed), and the user’s current context is used to retrieveTable 3 INSPEC annotation rating breakdown (5 5best)
General
RelevanceSection
RelevanceUsefulness
Score 51 16% 21% 32%
Score 52 16% 9% 18%
Score 53 21% 16% 15%
Score 54 17% 19% 18%
Score 55 30% 35% 17%
Average score 3.3 3.4 2.7
Error 0.3 0.3 0.3
RHODES AND MAES IBM SYSTEMS JOURNAL, VOL 39, NOS 3&4, 2000 700
Authorized licensed use limited to: Georgia Institute of Technology. Downloaded on September 10,2020 at 15:52:31 UTC from IEEE Xplore.  Restrictions apply.  this information. Letizia does just the opposite: the
source of information is the Web pages, and doc-uments are suggested based on the user’s proﬁle thatchanges over the course of hours or days. Letizia alsoshows the entirety of a recommended Web page ina separate window rather than presenting a summaryof potential hits and letting the user pick which sug-gestions to view.
Kenjin**
29is a brand new commercial product by
Autonomy that, according to user guides and press
releases, provides information from product data-bases, Web searches, or the user’s personal computerthat are related to information in currently runningapplications. Being a commercial product and hav-ing just been released, few details are available.
Finally,
RADAR11is a different front end for the Re-
membrance Agent that uses Microsoft Word instead
of Emacs and displays suggestions in a separate win-dow.
RADAR was built in collaboration with the JITIR
work described here, and also uses Savant as the in-formation-retrieval engine.
There are also several
JITIR agents that proactively
provide information based on local context but are
domain-speciﬁc.
Fixit30is an expert system for copy machine repair
that automatically brings up manual pages relating
to the fault being diagnosed. It uses the table of con-tents for the repair manual to ﬁnd useful pages, basedon the diagnosis produced by the expert system. Al-though the techniques used were domain-dependent,the corpus (manual pages) was still a legacy systemand did not need to be hand-coded for the system.
WebWatcher
31is similar to Letizia, highlighting hy-
perlinks that best match a user’s stated interest. As
with Letizia, recommendations are only pulled fromlinks on the page currently being viewed, based ona user proﬁle. However, in WebWatcher, recom-mended links are indicated by surrounding the linkwith a special icon. The system gives no further in-formation about the link or why one might want tofollow it. WebWatcher uses the topology of links be-tween Web pages to make recommendations and istherefore only applicable to the Web.
The Peace, Love, and Understanding Machine
(
PLUM ) system32will automatically add hyperlinks
to disaster news stories to better give a reader a per-sonalized understanding of the news. For example,a report that 220 people were killed in an earthquakein a small town in Japan would contain hyperlinksfrom the number “220” to a description of what per-centage of the population was killed and how manypeople that percentage would represent in the read-er’s own hometown.
Flyswat**
33is another recent commercial venture.
Flyswat operates as a plug-in to a Web browser and
highlights words or phrases it identiﬁes in a data-base. Clicking on the highlight can lead to dictionaryor thesaurus lookups or e-commerce pages that willsell products related to the word.
JITIR agents also share similarities with many per-
sonalized information systems. Of these, the mostrelevant are Lifestreams,
34the Forget-Me-Not sys-
tem,35–37and Lotus Agenda**.38All these systems
are designed to organize personal information withminimal user intervention. However, Forget-Me-Notis a direct memory aid, allowing users to search adatabase of their own automatically recorded pastactions. It falls into the same category as search en-gines and other interactive information retrieval sys-tems and is not designed to be proactive. Lifestreamsis an organizational structure to personal data ratherthan a
JITIR agent, though it does provide a notiﬁ-
cation system based on time. Agenda is a databaseprogram that includes contextual triggers that au-tomatically perform an action when data that meeta particular criterion are entered.
JITIR agents are also related to work in the area of
context-aware applications, especially those that usewearable computers. One such system is Audio Au-ra,
39an audio-based wearable computer that uses
ambient sound to automatically indicate e-mail,group activity, and location-based information. No-madic Radio
40is another audio-based wearable sys-
tem to deliver news, voice mail, and e-mail. In par-ticular, Nomadic Radio uses a concept called“dynamic scaling” that is quite similar to a rampinginterface. A third related system is the Context-Aware Archaeological Assistant,
41by which location
sensed by a GPSis used to provide ﬁeld notes about
animals in the area. This work is also related to manyefforts in augmented reality
42,43and ubiquitous com-
puting.44
Finally, several interface techniques have been de-veloped for presentation of information related tocurrent text, either automatically or by an author’sdesign. One such system is
VOIR ,45which combines
elements of a document with a user’s interest pro-ﬁle to automatically create hyperlinks. Another is
IBM SYSTEMS JOURNAL, VOL 39, NOS 3&4, 2000 RHODES AND MAES 701
Authorized licensed use limited to: Georgia Institute of Technology. Downloaded on September 10,2020 at 15:52:31 UTC from IEEE Xplore.  Restrictions apply.  the XLibris pen-based system,46which supports the
ability to hand-annotate documents using margin
links. Similarly, Fluid Links47allows Web designers
to create “glosses,” which are a way of presentinginformation incrementally.
Conclusions
In conclusion, just-in-time information retrieval
agents are systems that proactively provide informa-tion based on a person’s local context in a general,task-independent way. They are related to search en-gines, alarms, and news-clipping software, but differfrom each.
The Remembrance Agent, Margin Notes, and Jim-
miny have all been in use in the ﬁeld for over threeyears. Although controlled experiments are usefulfor validating theories, it is these experiments “in thewild” that give the best indication of what those the-ories should be. Reports from long-term users haveveriﬁed the assertion that
JITIR agents are not sim-
ply a substitute for a traditional search tool; usinga
JITIR agent changes how people use information
in ways that having a search engine alone does not.For example, the comments of the two controlled-experiment subjects that “I typed opinions, and the
RAgave me the facts to support them automatically”
have been repeated many times in conversations withlong-term users. Variations include users who an-swer more e-mailed questions than they normallywould because the
RAmakes it simple, and users be-
coming generally more aware of the historical con-text surrounding issues about which they are read-ing or writing.
It is also clear from long-term use that
JITIR agents
are situational applications: their effectiveness de-
pends a great deal on the environment in which theyare used. If the environment and the agent are mis-matched, for example, using the
INSPEC database
when writing e-mail about nonresearch, then the re-sults are not useful. Similarly, a database of personale-mail works well for the owner of that e-mail butdoes not produce results as good when used by an-other. These observations are the inspiration for de-signing techniques that are generally applicable, sothe agents can be adapted quickly to different do-mains, corpora, and individual preferences. It is alsothe inspiration for producing interfaces that are ig-norable, so the inevitable false-positive suggestionsdo not become more of a distraction than their oc-casional usefulness is worth.Acknowledgments
We would like to thank our sponsors at British Tele-
com and Merrill Lynch. We would also like to thankThad Starner, without whom the project would neverhave been started, and the
RAteam of Jesse Rabek,
Alex Park, Jesse Koontz, Pammie Mukerji, MatthewBurnside, Aneel Nazareth, Bayard Wenzel, and JanNelson, without whom the project would never havebeen completed. Finally, we would like to thank thereviewers of the papers that have been written onthis subject over the years, and the RemembranceAgent for bringing those reviewer comments to theforeground just when they were needed the most.
**Trademark or registered trademark of Yahoo! Inc., Microsoft
Corporation, The Open Group, Linus Torvalds, Reﬂection Tech-nology, Inc., Handykey Corporation, Insilco Corporation, Alta-Vista Company, Autonomy, Inc., Flyswat, Inc., or Lotus Devel-opment Corporation.
Cited references
1. B. Rhodes and T. Starner, “The Remembrance Agent: A Con-
tinuously Running Information Retrieval System,” The Pro-
ceedings of the First International Conference on Practical Ap-plications of Intelligent Agents and Multi-Agent Technology(PAAM’96), London (April 1996), pp. 486–495.
2. B. Rhodes, “Margin Notes: Building a Contextually Aware
Associative Memory,” Proceedings of the International Con-
ference on Intelligent User Interfaces (IUI’00), New Orleans,LA (January 9–12, 2000), pp. 219–224.
3. B. Rhodes, “The Wearable Remembrance Agent: A System
for Augmented Memory,” Personal Technologies: Special Is-
sue on Wearable Computing 1, 218–224 (1997).
4. T. Starner, Lizzy: MIT’s Wearable Computer Design 2.0.5,
http://www.media.mit.edu/wearables/lizzy/ (1997).
5. B. Rhodes, “Wearable Computing Meets Ubiquitous Com-
puting: Reaping the Best of Both Worlds,” The Third Inter-
national Symposium on Wearable Computers (ISWC’99), SanFrancisco, CA (October 18–19, 1999), pp. 141–149.
6. T. Starner, D. Kirsch, and S. Assefa, “The Locust Swarm: An
Environmentally-Powered, Networkless Location and Mes-saging System,” First International Symposium on Wearable
Computers (ISWC’97), Cambridge, MA (October 13–14,1997), pp. 169–170.
7. R. Want, A. Hopper, V. Falca
˜o, and J. Gibbons, “The Active
Badge Location System,” ACM Transactions on Information
Systems 10, No. 1, 91–102 (January 1992).
8. N. Minar, M. Gray, O. Roup, R. Krikorian, and P. Maes,
“Hive: Distributed Agents for Networking Things,” Proceed-
ings of the First International Symposium on Agent Systems andApplications and Third International Symposium on MobileAgents (ASA/MA’99) (1999), pp. 118–129.
9. S. E. Johnson, P. Jourlin, K. Spark Jones, and P. C. Wood-
land, “Spoken Document Retrieval for TREC-8 at CambridgeUniversity,” to appear in NIST Special Publication: The Eighth
Text REtrieval Conference (TREC 8) NIST, Gaithersburg, MD
(2000).
10. A. Pentland, B. Moghaddam, and T. Starner, “View-Based
and Modular Eigenspaces for Face Recognition,” Proceed-
ings of IEEE Conference on Computer Vision and Pattern Rec-ognition, Seattle, WA (June 1994), pp. 21–23.
RHODES AND MAES IBM SYSTEMS JOURNAL, VOL 39, NOS 3&4, 2000 702
Authorized licensed use limited to: Georgia Institute of Technology. Downloaded on September 10,2020 at 15:52:31 UTC from IEEE Xplore.  Restrictions apply.  11. I. B. Crabtree, S. Soltysiak, and M. Thint, “Adaptive Personal
Agents,” Personal Technologies 2, No. 3, 141–151 (1998).
12. S. Robertson, S. Walker, and M. Beaulieu, “Okapi at TREC-7:
Automatic ad hoc, Filtering, VLC and Interactive,” NIST Spe-
cial Publication 500-242: The Seventh Text REtrieval Confer-
ence (TREC 7), NIST, Gaithersburg, MD (1999), pp. 253–264.
13. B. Rhodes, Just-in-Time Information Retrieval, Ph.D. disser-
tation, MIT, Media Arts and Sciences, Cambridge, MA (June2000).
14. G. K. Zipf, Human Behavior and the Principle of Least Effort:
An Introduction to Human Ecology , Addison-Wesley Publish-
ing Co., Reading, MA (1949).
15. J. Payne, J. Bettman, and E. Johnson, The Adaptive Decision
Maker, Cambridge University Press, Cambridge, UK (1993).
16. S. Jarvenpaa, “The Effect of Task Demands and Graphical
Format on Information Processing Strategies,” Management
Science 35, 285–303 (1989).
17. J. Russo, “The Value of Unit Price Information,” Journal of
Marketing Research 14, 193–201 (1977).
18. R. Miller, “Response Time in Man-Computer Conversational
Transactions,” AFIPS Conference Proceedings of the Fall Joint
Computer Conference 33, Part 1 (1968), pp. 267–277.
19. B. Jansen, A. Spink, and J. Bateman, “Searchers, the Sub-
jects They Search, and Sufﬁciency: A Study of a Large Sam-ple of EXCITE Searches,” Proceedings of WebNet-98 (1998).
20. D. Harman, “Overview of the Third Text REtrieval Confer-
ence (TREC-3),” NIST Special Publication 500-226: Overview
of the Third Text REtrieval Conference (TREC-3) , NIST, Gaith-
ersburg, MD (1995), pp. 1–20.
21. D. Hull, “The TREC-7 Filtering Track: Description and Anal-
ysis,” NIST Special Publication 500-242: The Seventh Text RE-
trieval Conference (TREC 7), NIST, Gaithersburg, MD (1998),pp. 33–56.
22. C. D. Wickens, Engineering Psychology and Human Perfor-
mance, Second Edition, Harper Collins Publishers, New York
(1992).
23. Wickens, op. cit., p. 98.
24. Y. Miyata and D. Norman, “Psychological Issues in Support
of Multiple Activities,” User Centered System Design, D. Nor-
man and S. Draper, Editors, Lawrence Erlbaum Associates,Inc., Hillsdale, NJ (1986).
25.The Tech Archive Search, see http://www-tech.mit.edu/search.
html.
26. J. Budzik and K. Hammond, “Watson: Anticipating and Con-
textualizing Information Needs,” Proceedings of the Sixty-Sec-
ond Annual Meeting of the American Society for InformationScience (1999).
27. P. Maglio, R. Barrett, C. Campbell, and T. Selker, “SUIT-
OR: An Attentive Information System,” The Proceedings of
the International Conference on Intelligent User Interfaces
(IUI’00), Henry Lieberman, Editor, ACM Press (January9–12, 2000), pp. 169–176.
28. H. Lieberman, “Autonomous Interface Agents,” Proceedings
of CHI’97, Atlanta, GA (March 1997), pp. 67–74.
29. Autonomy, Inc., San Francisco, CA, see http://www.
kenjin.com.
30. P. Hart and J. Graham, “Query-Free Information Retriev-
al,”IEEE Expert/Intelligent Systems & Their Applications 12,
No. 5, 32–37 (September, October 1997).
31. T. Joachims, D. Freitag, and T. Mitchell, “WebWatcher: A
Tour Guide for the World Wide Web,” International Joint
Conference on Artiﬁcial Intelligence (August 1997), pp. 770–
775.32. S. Elo, PLUM: Contextualizing News for Communities Through
Augmentation, master’s thesis, MIT, Media Arts and Sciences,
Cambridge, MA (1995).
33. Flyswat, Inc., see http://www.ﬂyswat.com.34. E. Freeman and D. Gelernter, “Lifestreams: A Storage Model
for Personal Data,” ACM SIGMOD Bulletin, 80–86 (March
1996).
35. M. Lamming, P. Brown, K. Carter, M. Eldridge, M. Flynn,
and G. Louie, “The Design of a Human Memory Prosthe-sis,” The Computer Journal 37, No. 3, 153–163 (1994).
36. M. Lamming and M. Flynn, “Forget-Me-Not: Intimate Com-
puting in Support of Human Memory,” Friend21: International
Symposium on Next Generation Human Interface , Meguro Ga-
joen, Japan (1994), pp. 125–128.
37. P. Brown, J. Bovey, and X. Chen, “Context-Aware Applica-
tions: From the Laboratory to the Marketplace,” IEEE Per-
sonal Communications 4, No. 5, 58–63 (October 1997).
38. S. Kaplan, M. Kapor, E. Belove, R. Landsman, and T. Drake,
“Agenda: A Personal Information Manager,” Communica-
tions of the ACM 33, No. 7, 105–116 (July 1990).
39. E. Mynatt, M. Back, and R. Want, “Designing Audio Aura,”
Proceedings of the Conference on Human Factors in Comput-ing Systems (CHI’98), ACM Press (1998), pp. 566–573.
40. N. Sawhney and C. Schmandt, “Nomadic Radio: Scalable and
Contextual Notiﬁcation for Wearable Audio Messaging,” Pro-
ceedings of the ACM SICHI Conference on Human Factors inComputing Systems, Pittsburgh, PA (May 15–20, 1999), pp.96–103.
41. N. Ryan, J. Pascoe, and D. Morse, “Enhanced Reality Field-
work: The Context-Aware Archaeological Assistant,”V. Gaffney, M. van Leusen, and S. Exxon, Editors, Computer
Applications in Archaeology (1997, 1998).
42. J. Rekimoto, Y. Ayatsuka, and K. Hayashi, “Augmentable
Reality: Situated Communications Through Physical and Dig-ital Spaces,” Digest of Papers: The Second International Sym-
posium on Wearable Computers, Pittsburgh, PA, IEEE Com-puter Society (October 19–20, 1998), pp. 68–75.
43. S. Feiner, B. MacIntyre, and D. Seligmann, “Knowledge-
Based Augmented Reality,” Communications of the ACM 36,
No. 7, 52–62 (July 1993).
44. M. Weiser, “Some Computer Science Issues in Ubiquitous
Computing,” Communications of the ACM 36, No. 7, 75–84
(July 1993).
45. G. Golovchinsky, “What the Query Told the Link: The In-
tegration of Hypertext and Information Retrieval,” The Pro-
ceedings of HyperText’97, Southampton, UK, ACM Press(1997), pp. 67–74.
46. M. Price, G. Golovchinsky, and B. Schilit, “Linking by Ink-
ing: Trailblazing in a Paper-Like Hypertext,” The Proceed-
ings of HyperText’98 , Pittsburgh, PA, ACM Press (June 1998),
pp. 30–39.
47. P. Zellweger, B. Chang, and J. Mackinlay, “Fluid Links for
Informed and Incremental Link Transitions,” The Proceed-
ings of HyperText’98 , Pittsburgh, PA, ACM Press (June 1998),
pp. 50–57.
Accepted for publication April 13, 2000.
Bradley J. Rhodes MIT Media Laboratory, 20 Ames Street, Cam-
bridge, Massachusetts 02139-4307 (electronic mail: rhodes@media.mit.edu). Dr. Rhodes is a recent graduate of MIT’s Media Lab,
where he worked under the direction of Pattie Maes in the Soft-ware Agents Group. His research areas included the study of in-telligence augmentation, just-in-time information retrieval, ubiq-uitous computing, context-aware applications, and wearable
IBM SYSTEMS JOURNAL, VOL 39, NOS 3&4, 2000 RHODES AND MAES 703
Authorized licensed use limited to: Georgia Institute of Technology. Downloaded on September 10,2020 at 15:52:31 UTC from IEEE Xplore.  Restrictions apply.  computing. He is one of the “Media Lab Cyborgs” and for the
past four years has been an active member of the MIT WearableComputing Project. He received his Ph.D. degree from the MITMedia Lab in 2000, his S.M. degree from the MIT Media Labin 1996, and an S.B. degree in computer science from MIT in1992.
Pattie Maes MIT Media Laboratory, 20 Ames Street, Cambridge,
Massachusetts 02139-4307 (electronic mail: pattie@media.mit.edu).
Dr. Maes is an associate professor at MIT’s Media Lab, whereshe founded and directs the Software Agents Group and is prin-cipal investigator of the Media Lab e-markets Special InterestGroup. Her team’s work has included personalized informationﬁltering agents, agents that automate behavior patterns, match-making agents, just-in-time information retrieval agents, andagents that buy and sell on behalf of a user. Dr. Maes receivedher doctoral degree in computer science and artiﬁcial intelligencefrom the Vrije Universiteit Brussel in Belgium in 1987.
RHODES AND MAES IBM SYSTEMS JOURNAL, VOL 39, NOS 3&4, 2000 704
Authorized licensed use limited to: Georgia Institute of Technology. Downloaded on September 10,2020 at 15:52:31 UTC from IEEE Xplore.  Restrictions apply.  